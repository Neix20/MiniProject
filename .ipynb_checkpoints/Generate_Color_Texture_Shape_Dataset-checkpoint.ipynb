{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-genre",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-township",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-harbor",
   "metadata": {},
   "source": [
    "### List all Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "relative-bryan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset\\\\Apple\\\\',\n",
       " 'Dataset\\\\Grape\\\\',\n",
       " 'Dataset\\\\Lemon\\\\',\n",
       " 'Dataset\\\\Limes\\\\',\n",
       " 'Dataset\\\\Lychee\\\\',\n",
       " 'Dataset\\\\Pear\\\\']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folders = glob('Dataset/*/')\n",
    "image_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-thesis",
   "metadata": {},
   "source": [
    "### List all images in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "light-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = image_folders[0]\n",
    "folder_name = folder_path.split(\"\\\\\")[1]\n",
    "all_image_in_folder = glob(folder_path + \"*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-addition",
   "metadata": {},
   "source": [
    "### List Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprised-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = all_image_in_folder[0]\n",
    "label = folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-colleague",
   "metadata": {},
   "source": [
    "### Load Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generic-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-albany",
   "metadata": {},
   "source": [
    "### Use OpenCV To Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "otherwise-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-seeker",
   "metadata": {},
   "source": [
    "### Remove White Background (Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "selected-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(img, threshold):\n",
    "    \"\"\"\n",
    "    This method removes background from your image\n",
    "    \n",
    "    :param img: cv2 image\n",
    "    :type img: np.array\n",
    "    :param threshold: threshold value for cv2.threshold\n",
    "    :type threshold: float\n",
    "    :return: RGBA image\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshed = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "    mask = cv2.drawContours(threshed, cnt, 0, (0, 255, 0), 0)\n",
    "    masked_data = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    dst = masked_data[y: y + h, x: x + w]\n",
    "\n",
    "    dst_gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    _, alpha = cv2.threshold(dst_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    b, g, r = cv2.split(dst)\n",
    "\n",
    "    rgba = [r, g, b, alpha]\n",
    "    dst = cv2.merge(rgba, 4)\n",
    "    \n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-proxy",
   "metadata": {},
   "source": [
    "### Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    plt.imshow (img, interpolation = 'nearest')\n",
    "    _ = plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "based-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (32, 32),interpolation = cv2.INTER_AREA)\n",
    "img = remove_background(img, 225)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"F.jpg\", img)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-growth",
   "metadata": {},
   "source": [
    "### Display Plot Image Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_grid(images, nb_rows, nb_cols, figsize=(5, 5)):\n",
    "    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=figsize)\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(0, nb_rows):\n",
    "        for j in range(0, nb_cols):\n",
    "            axs[i, j].imshow(images[n], interpolation = 'nearest')\n",
    "            axs[i, j].axis('off')\n",
    "            n += 1       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-equilibrium",
   "metadata": {},
   "source": [
    "### Reshape Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amino-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.array(img)\n",
    "img_flatten = img_arr.reshape(1, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-treaty",
   "metadata": {},
   "source": [
    "### Squeeze Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharp-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_squeeze = np.squeeze(img_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-princess",
   "metadata": {},
   "source": [
    "## Color Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-airport",
   "metadata": {},
   "source": [
    "### Convert Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_val_to_rgb(x):\n",
    "#     if x >= 0 and x < 64:\n",
    "#         return \"00\"\n",
    "#     elif x >= 64 and x < 128:\n",
    "#         return \"55\"\n",
    "#     elif x >= 128 and x < 192:\n",
    "#         return \"AA\"\n",
    "#     else:\n",
    "#         return \"FF\"\n",
    "    \n",
    "# def convert_val_to_bin(x):\n",
    "#     if x >= 0 and x < 64:\n",
    "#         return 0\n",
    "#     elif x >= 64 and x < 128:\n",
    "#         return 85\n",
    "#     elif x >= 128 and x < 192:\n",
    "#         return 170\n",
    "#     else:\n",
    "#         return 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improved-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_val_to_rgb(x):\n",
    "#     if x >= 0 and x < 42.5:\n",
    "#         return \"00\"\n",
    "#     elif x >= 42.5 and x < 85:\n",
    "#         return \"33\"\n",
    "#     elif x >= 85 and x < 127.5:\n",
    "#         return \"66\"\n",
    "#     elif x >= 127.5 and x < 170:\n",
    "#         return \"99\"\n",
    "#     elif x >= 170 and x < 212.5:\n",
    "#         return \"CC\"\n",
    "#     else:\n",
    "#         return \"FF\" \n",
    "    \n",
    "# def convert_val_to_bin(x):\n",
    "#     if x >= 0 and x < 42.5:\n",
    "#         return 42\n",
    "#     elif x >= 42.5 and x < 85:\n",
    "#         return 84\n",
    "#     elif x >= 85 and x < 127.5:\n",
    "#         return 127\n",
    "#     elif x >= 127.5 and x < 170:\n",
    "#         return 169\n",
    "#     elif x >= 170 and x < 212.5:\n",
    "#         return 212\n",
    "#     else:\n",
    "#         return 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vocational-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_val_to_rgb(x):\n",
    "    if x >= 0 and x < 32:\n",
    "        return \"00\"\n",
    "    elif x >= 32 and x < 64:\n",
    "        return \"24\"\n",
    "    elif x >= 64 and x < 96:\n",
    "        return \"40\"\n",
    "    elif x >= 96 and x < 128:\n",
    "        return \"60\"\n",
    "    elif x >= 128 and x < 160:\n",
    "        return \"80\"\n",
    "    elif x >= 160 and x < 192:\n",
    "        return \"A0\"\n",
    "    elif x >= 192 and x < 224:\n",
    "        return \"C0\"\n",
    "    else:\n",
    "        return \"FF\"\n",
    "\n",
    "def convert_val_to_bin(x):\n",
    "    if x >= 0 and x < 32:\n",
    "        return 31\n",
    "    elif x >= 32 and x < 64:\n",
    "        return 63\n",
    "    elif x >= 64 and x < 96:\n",
    "        return 95\n",
    "    elif x >= 96 and x < 128:\n",
    "        return 127\n",
    "    elif x >= 128 and x < 160:\n",
    "        return 159\n",
    "    elif x >= 160 and x < 192:\n",
    "        return 191\n",
    "    elif x >= 192 and x < 224:\n",
    "        return 223\n",
    "    else:\n",
    "        return 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integral-split",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_val_to_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-07c47d228674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_convert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_val_to_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_squeeze\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# img_squeeze = np.vectorize(convert_val_to_bin)(img_squeeze)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_val_to_rgb' is not defined"
     ]
    }
   ],
   "source": [
    "img_convert = np.vectorize(convert_val_to_rgb)(img_squeeze)\n",
    "# img_squeeze = np.vectorize(convert_val_to_bin)(img_squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2d_arr = img_convert.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-freedom",
   "metadata": {},
   "source": [
    "### Convert to List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_arr = img_2d_arr.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-weekend",
   "metadata": {},
   "source": [
    "### Convert to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_str = lambda x:\"#\"+\"\".join(list(map(str, x)))\n",
    "img_str_arr = [convert_to_str(x) for x in img_list_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-hampton",
   "metadata": {},
   "source": [
    "### Get Frequency of Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-monitoring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_arr = np.array(img_str_arr)\n",
    "np.unique(new_arr, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-sherman",
   "metadata": {},
   "source": [
    "### Convert Image to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = {a:b for (a,b) in zip(np.unique(new_arr, return_counts=True)[0], np.unique(new_arr, return_counts=True)[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-builder",
   "metadata": {},
   "source": [
    "## Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_1d(img_path, convert_func, threshold = 225, h = 100, w = 100):\n",
    "    cv_img = cv2.imread(img_path)\n",
    "    cv_img = cv2.resize(cv_img, (w,h),interpolation = cv2.INTER_AREA)\n",
    "    cv_img = remove_background(cv_img, threshold)\n",
    "    img_arr = np.array(cv_img)\n",
    "    img_flatten = img_arr.reshape(1, -1).T\n",
    "    img_squeeze = np.squeeze(img_flatten)\n",
    "    img_convert = np.vectorize(convert_func)(img_squeeze)\n",
    "    return img_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-courage",
   "metadata": {},
   "source": [
    "## Color Features Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_color(cv_img):\n",
    "    img_arr = np.array(cv_img)\n",
    "    img_flatten = img_arr.reshape(1, -1).T\n",
    "    img_squeeze = np.squeeze(img_flatten)\n",
    "    img_convert = np.vectorize(convert_val_to_rgb)(img_squeeze)\n",
    "    img_2d_arr = img_convert.reshape(-1, 3)\n",
    "    img_list_arr = img_2d_arr.tolist()\n",
    "    convert_to_str = lambda x:\"#\"+\"\".join(list(map(str, x)))\n",
    "    img_str_arr = [convert_to_str(x) for x in img_list_arr]\n",
    "    new_arr = np.array(img_str_arr)\n",
    "    tmp_dict = {a:b for (a,b) in zip(np.unique(new_arr, return_counts=True)[0], np.unique(new_arr, return_counts=True)[1])}\n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-occasion",
   "metadata": {},
   "source": [
    "### Use OpenCV To Show Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path, -1)\n",
    "color = ('b','g','r')\n",
    "for channel,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[channel],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-guide",
   "metadata": {},
   "source": [
    "### Original Image (24-bit Color Palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "display(img)\n",
    "img = np.array(img)\n",
    "img = img.reshape(-1, 3)\n",
    "tmp_df = pd.DataFrame(img, columns = [\"r\", \"g\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-trout",
   "metadata": {},
   "source": [
    "### Original Image Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tmp_df[\"b\"],256,[0,256], color=\"blue\")\n",
    "plt.hist(tmp_df[\"g\"],256,[0,256], color=\"green\")\n",
    "plt.hist(tmp_df[\"r\"],256,[0,256], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-folder",
   "metadata": {},
   "source": [
    "### New Image (6-bit Color Palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-sucking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = w = 100\n",
    "new_img = pipeline_1d(img_path, convert_val_to_bin, 225, h, w)\n",
    "new_img = new_img.reshape(h, w, 3)\n",
    "display(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-colleague",
   "metadata": {},
   "source": [
    "### Show 300 Image (24-bit Color Palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-township",
   "metadata": {},
   "source": [
    "### Convert Image Path to OpenCV Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_path_to_cv_img(img_path_arr, threshold = 225, h = 100, w = 100):\n",
    "    img_arr = []\n",
    "    for img_path in img_path_arr:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (w,h),interpolation = cv2.INTER_AREA)\n",
    "        img = remove_background(img, threshold)\n",
    "        img_arr.append(img)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-continuity",
   "metadata": {},
   "source": [
    "### Display First 300 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_300(folder_path, threshold = 225, h = 100, w = 100):\n",
    "    folder_name = folder_path.split(\"\\\\\")[1]\n",
    "    all_images = glob(folder_path + \"*.jpg\")\n",
    "    all_images = all_images[0:300]\n",
    "    img_arr = convert_img_path_to_cv_img(all_images, threshold, h, w)\n",
    "    plot_img_grid(img_arr, 15, 15, (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-corrections",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for folder_path in glob('Dataset/*/'):\n",
    "#     show_300(folder_path, 225, 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-million",
   "metadata": {},
   "source": [
    "### Show 300 Image (6-bit Color Palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-dictionary",
   "metadata": {},
   "source": [
    "### Convert Image Path to OpenCV Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_path_to_new_cv_img(img_path_arr, threshold = 225, h = 100, w = 100):\n",
    "    img_arr = []\n",
    "    for img_path in img_path_arr:\n",
    "        new_img = pipeline_1d(img_path, convert_val_to_bin,threshold, h, w)\n",
    "        new_img = new_img.reshape(h, w, 3)\n",
    "        img_arr.append(new_img)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-carpet",
   "metadata": {},
   "source": [
    "### Display First 300 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_300_new(folder_path, threshold = 225, h = 100, w = 100):\n",
    "    folder_name = folder_path.split(\"\\\\\")[1]\n",
    "    all_images = glob(folder_path + \"*.jpg\")\n",
    "    all_images = all_images[0:300]\n",
    "    img_arr = convert_img_path_to_new_cv_img(all_images, threshold, h, w)\n",
    "    plot_img_grid(img_arr, 15, 15, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder_path in glob('Dataset/*/'):\n",
    "#     show_300_new(folder_path, 225, 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-loading",
   "metadata": {},
   "source": [
    "### New Image Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-testament",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_img = new_img.reshape(-1, 3)\n",
    "tmp_df = pd.DataFrame(new_img, columns = [\"b\", \"g\", \"r\"])\n",
    "plt.hist(tmp_df[\"b\"],256,[0,1], color=\"blue\")\n",
    "plt.hist(tmp_df[\"g\"],256,[0,1], color=\"green\")\n",
    "plt.hist(tmp_df[\"r\"],256,[0,1], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-fairy",
   "metadata": {},
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-blanket",
   "metadata": {},
   "source": [
    "### Convert New Image to OpenCV Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img = cv2.imread(img_path)\n",
    "cv_img = remove_background(cv_img, 225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-quarter",
   "metadata": {},
   "source": [
    "### Convert Image to GrayScale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img = cv2.imread(img_path)\n",
    "cv_img = remove_background(cv_img, 225)\n",
    "\n",
    "# Convert Image to Gray Image\n",
    "img_gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-interface",
   "metadata": {},
   "source": [
    "### Get Mean of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(img_gray)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-determination",
   "metadata": {},
   "source": [
    "### Get Variance of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = np.var(img_gray)\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-small",
   "metadata": {},
   "source": [
    "### Get Entropy of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = skimage.measure.shannon_entropy(img_gray)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-reservation",
   "metadata": {},
   "source": [
    "### Get Gray Level Occurrence of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm = greycomatrix(img_gray, [2], [0], 256, symmetric = True, normed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-maine",
   "metadata": {},
   "source": [
    "### Get Contrast of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = greycoprops(glcm, prop=\"contrast\").item()\n",
    "contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-privilege",
   "metadata": {},
   "source": [
    "### Get Homogeneity of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity = greycoprops(glcm, prop=\"homogeneity\").item()\n",
    "homogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-mercy",
   "metadata": {},
   "source": [
    "### Get Correlation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = greycoprops(glcm, prop=\"correlation\").item()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-monte",
   "metadata": {},
   "source": [
    "### Get Energy of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = greycoprops(glcm, prop=\"energy\").item()\n",
    "energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-insurance",
   "metadata": {},
   "source": [
    "### Texture Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_texture(img_gray):\n",
    "    tmp_dict = {}\n",
    "    tmp_dict[\"Mean\"] = np.mean(img_gray)\n",
    "    tmp_dict[\"Variance\"] = np.var(img_gray)\n",
    "    tmp_dict[\"Entropy\"] = skimage.measure.shannon_entropy(img_gray)\n",
    "    glcm = greycomatrix(img_gray, [2], [0], 256, symmetric = True, normed = True)\n",
    "    tmp_dict[\"Contrast\"] = greycoprops(glcm, prop=\"contrast\").item()\n",
    "    tmp_dict[\"Homogeneity\"] = greycoprops(glcm, prop=\"homogeneity\").item()\n",
    "    tmp_dict[\"Correlation\"] = greycoprops(glcm, prop=\"correlation\").item()\n",
    "    tmp_dict[\"Energy\"] = greycoprops(glcm, prop=\"energy\").item()\n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-console",
   "metadata": {},
   "source": [
    "## Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_shape(img_gray):\n",
    "    # Apply Gaussian Blur to Image\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (7,7), 1)\n",
    "\n",
    "    # Canny Edge Detection\n",
    "    img_canny = cv2.Canny(img_blur, 50, 150)\n",
    "\n",
    "    # Edge Detector\n",
    "    kernel = np.ones((5, 5), dtype = np.uint8)\n",
    "    img_dilate = cv2.dilate(img_canny, kernel, iterations = 2)\n",
    "\n",
    "    contours, hier = cv2.findContours(img_dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    area, peri = 0, 0\n",
    "    mu, huMoments = [], []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        mu = cv2.moments(cnt)\n",
    "        huMoments = cv2.HuMoments(mu)\n",
    "        \n",
    "    for i in range(0,7):\n",
    "        huMoments[i] = -1* math.copysign(1.0, huMoments[i]) * math.log10(abs(huMoments[i]) if abs(huMoments[i]) > 0 else 1)\n",
    "    \n",
    "    tmp_dict = {}\n",
    "    tmp_dict[\"Area\"] = area\n",
    "    tmp_dict[\"Perimeter\"] = peri\n",
    "    for (i, huMoment) in enumerate(huMoments):\n",
    "        tmp_dict[f\"huMoment {(i + 1)}\"] = huMoment[0]\n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-carol",
   "metadata": {},
   "source": [
    "### Gray Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img = cv2.imread(img_path)\n",
    "cv_img = remove_background(cv_img, 225)\n",
    "\n",
    "# Convert Image to Gray Image\n",
    "img_gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-shakespeare",
   "metadata": {},
   "source": [
    "### Get Area of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pipeline_shape(img_gray)[\"Area\"]\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-cooking",
   "metadata": {},
   "source": [
    "### Get Perimeter of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "peri = pipeline_shape(img_gray)[\"Perimeter\"]\n",
    "peri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-research",
   "metadata": {},
   "source": [
    "### Get Moments of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipeline_shape(img_gray)\n",
    "huMoments = [tmp[f\"huMoment {(i + 1)}\"] for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, huMoment) in enumerate(huMoments):\n",
    "    print(f\"huMoment {(i + 1)} : {huMoment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-muslim",
   "metadata": {},
   "source": [
    "### Update Final Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_final(img_path,alpha = 1.5, beta = 0, threshold = 225, w = 100, h = 100):\n",
    "    final_dict = {}\n",
    "    \n",
    "    cv_img = cv2.imread(img_path)\n",
    "    \n",
    "    # Resize Image\n",
    "    cv_img = cv2.resize(cv_img, (w,h),interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Remove White Background\n",
    "    cv_img = remove_background(cv_img, threshold)\n",
    "    \n",
    "    # Convert Image from RGB to BGR\n",
    "    cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get Color Features\n",
    "    color_feature_dict = pipeline_color(cv_img)\n",
    "    final_dict.update(color_feature_dict)\n",
    "    \n",
    "    # Convert Image to Gray Image\n",
    "    img_gray = cv2.cvtColor(cv_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Get Texture Features\n",
    "    texture_feature_dict = pipeline_texture(img_gray)\n",
    "    final_dict.update(texture_feature_dict)\n",
    "\n",
    "    # Get Shape Features\n",
    "    shape_feature_dict = pipeline_shape(img_gray)\n",
    "    final_dict.update(shape_feature_dict)\n",
    "    \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_final(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-cross",
   "metadata": {},
   "source": [
    "### Get minimum number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image_arr = []\n",
    "for folder_path in glob('Dataset/*/'):\n",
    "    folder_name = folder_path.split(\"\\\\\")[1]\n",
    "    all_images = glob(folder_path + \"*.jpg\")\n",
    "    num_image_arr.append(len(all_images))\n",
    "min_num_of_img = min(num_image_arr)\n",
    "min_num_of_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-palestinian",
   "metadata": {},
   "source": [
    "### Append To Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_arr = []\n",
    "# cc = [\"00\", \"55\", \"AA\", \"FF\"]\n",
    "# cc = [\"00\", \"33\", \"66\", \"99\", \"CC\", \"FF\"]\n",
    "cc = [\"00\", \"24\", \"40\", \"60\", \"80\", \"A0\", \"C0\", \"FF\"]\n",
    "for i in cc:\n",
    "    for j in cc:\n",
    "        for k in cc:\n",
    "            feature_arr.append(f\"#{i}{j}{k}\")\n",
    "huMoment = [f\"huMoment {(i + 1)}\" for i in range(7)]\n",
    "feature_arr += [\"Mean\", \"Variance\", \"Entropy\", \"Contrast\", \"Homogeneity\", \"Correlation\", \"Energy\"]\n",
    "feature_arr += huMoment\n",
    "feature_arr += [\"Area\", \"Perimeter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = feature_arr)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-wildlife",
   "metadata": {},
   "source": [
    "### Generate CSV (Color, Texture and Shape Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 225\n",
    "h = w = 100\n",
    "for folder_path in glob('Dataset/*/'):\n",
    "    folder_name = folder_path.split(\"\\\\\")[1]\n",
    "    all_images = glob(folder_path + \"*.jpg\")\n",
    "    all_images = all_images[0:min_num_of_img]\n",
    "    for img_path in all_images:\n",
    "        feature_dict = pipeline_final(img_path, threshold, h, w)\n",
    "        final_df = final_df.append(feature_dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-forwarding",
   "metadata": {},
   "source": [
    "### Fill in Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-relaxation",
   "metadata": {},
   "source": [
    "### Add Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name_arr = [folder_path.split(\"\\\\\")[1] for folder_path in glob('Dataset/*/')]\n",
    "label_arr = list(itertools.chain.from_iterable(itertools.repeat(x, min_num_of_img) for x in folder_name_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"Label\"] = label_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-moses",
   "metadata": {},
   "source": [
    "### Shuffle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-punch",
   "metadata": {},
   "source": [
    "### Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Image_Dataset_Color_Texture_Shape_Features.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-ukraine",
   "metadata": {},
   "source": [
    "### Generate CSV (After Color Discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_img_arr = []\n",
    "# h = w = 100\n",
    "# for folder_path in glob('Dataset/*/'):\n",
    "#     folder_name = folder_path.split(\"\\\\\")[1]\n",
    "#     all_images = glob(folder_path + \"*.jpg\")\n",
    "#     all_images = all_images[0:min_num_of_img]\n",
    "#     for img_path in all_images:\n",
    "#         img = Image.open(img_path)\n",
    "#         # Get Hex Value Only\n",
    "#         new_img = pipeline_1d(img, convert_val_to_bin, h, w)\n",
    "#         all_img_arr.append(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_img_arr)\n",
    "# df.rename(columns={i:f'Pixel {i}' for i in range(h * w *3)}, inplace = True)\n",
    "# folder_name_arr = [folder_path.split(\"\\\\\")[1] for folder_path in glob('Dataset/*/')]\n",
    "# label_arr = list(itertools.chain.from_iterable(itertools.repeat(x, min_num_of_img) for x in folder_name_arr))\n",
    "# df[\"Label\"] = label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle Dataset\n",
    "# df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"Image_Dataset_Color_Features_Float.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
